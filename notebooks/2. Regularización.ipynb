{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regularización\n",
    "\n",
    "En este notebook se revisarán los conceptos de:\n",
    "\n",
    "1. Regularización en regresión\n",
    "    1. Ridge regression\n",
    "    2. Lasso \n",
    "2. Regularización en clasificación\n",
    "    1. Regresión logística\n",
    "\n",
    "Primero cargamos librerías y funciones necesarias, incluyendo las del módulo `utils`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_decision_boundary, plot_decision_boundary_poly, CM_BRIGHT\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Regularización sobre algoritmos de regresión.\n",
    "\n",
    "Vamos a trabajar sobre el mismo ejemplo que vimos en la clase anterior para entender el concepto de regularización. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_train = 10\n",
    "N_test  = 100\n",
    "\n",
    "# función verdadera g(x)\n",
    "x = np.linspace(0,1,N_test)\n",
    "g_x = np.cos(1.5*np.pi*x)\n",
    "\n",
    "# proceso y\n",
    "np.random.seed(0) # para asegurar reproducibilidad\n",
    "epsilon = np.random.randn(N_test) * 0.2\n",
    "y = g_x + epsilon\n",
    "\n",
    "# Datos: D = {x_i,y_i}, obtenemos una muestra\n",
    "idx = np.random.randint(0,N_test,N_train)\n",
    "x_i = x[idx]\n",
    "y_i = y[idx]\n",
    "\n",
    "# dibujamos la función g(x), y el conjunto de datos x_i,y_i\n",
    "plt.plot(x,g_x,'r',label='y')\n",
    "plt.plot(x_i,y_i,'b.',label='Training set')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, ajustamos un modelo (regresión lineal) muy complejo sobre estos datos, de la forma:\n",
    "\n",
    "$$f_{\\omega}(x) = \\omega_0 + \\sum_{j=1}^{10}\\omega_j x^j$$\n",
    "\n",
    "el cual tiene 10 coeficientes ($\\omega_1,\\ldots,\\omega_{10}$). Este modelo seguramente sufrirá de overfitting.\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 2.1: Entrena un algoritmo de regresión lineal y calcula el error cuadrático medio del conjunto de test\n",
    "</div>\n",
    "\n",
    "Error cuadrático medio: $$MSE = \\frac{1}{N}\\sum_{i=1}^N \\left(y^{(i)}-\\hat{y}^{(i)}\\right)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "degree = 10\n",
    "\n",
    "# features\n",
    "poly = PolynomialFeatures(degree) # generamos x^j\n",
    "X_train = poly.fit_transform(x_i.reshape(-1, 1))\n",
    "y_train = y_i\n",
    "\n",
    "X_test = poly.fit_transform(x.reshape(-1, 1))\n",
    "y_test = y\n",
    "\n",
    "# ... código aquí\n",
    "# pista: como siempre, instanciar el modelo y .fit()\n",
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "# predicción\n",
    "y_hat = lr.predict(X_test)\n",
    "\n",
    "# ... código aquí\n",
    "mse = np.mean(y-y_hat)*np.mean(y-y_hat) / y.size\n",
    "\n",
    "plt.plot(x,g_x,'r',label='$y$')\n",
    "plt.plot(x_i,y_i,'b.',label='$y_i$')\n",
    "plt.plot(x,y_hat,'g',label='$\\hat{y}$')\n",
    "plt.title(f'Grado: {degree}\\nMSE: {mse:.2f}')\n",
    "plt.legend()\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-2, 2))\n",
    "plt.show()\n",
    "\n",
    "# Mostramos los coeficientes del modelo\n",
    "print('w0: ', lr.intercept_)\n",
    "\n",
    "w = lr.coef_\n",
    "norm_w2 = np.dot(w,w.T) # no se tiene en cuenta el intercepto\n",
    "\n",
    "coef_names = ['w' + str(i) + ': ' for i in range(1,degree+1)]\n",
    "for f,wi in zip(coef_names,w):\n",
    "    print(f,wi)\n",
    "\n",
    "print(f'\\n||w||_2^2 = {norm_w2:.2g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 Ridge regression\n",
    "\n",
    "Se refiere al modelo de regresión lineal con penalización sobre la magnitud de los coeficientes\n",
    "\n",
    "$$\\min_{\\boldsymbol{\\omega}}|| \\mathbf{y} - \\mathbf{X}\\boldsymbol{\\omega}||_2^2 + \\alpha ||\\boldsymbol{\\omega} ||_2^2$$\n",
    "\n",
    "como medida contra el [*overfitting*](https://en.wikipedia.org/wiki/Overfitting)\n",
    "\n",
    "El modelo de [*ridge regression*](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html), tiene un parámetro libre ($\\alpha$) que hemos de fijar a priori. En otras palabras, tenemos que dar un valor a $\\alpha$ para que el modelo calcule los coeficientes $\\boldsymbol{\\omega}$. A tener en cuenta:\n",
    "\n",
    "* Si $\\alpha = 0$, entonces el resultado coincide con un modelo de [regresión lineal](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Pero ojo, no será igual, ya que sklearn trata de forma diferente Lasso con $\\alpha = 0$ y la regresión lineal\n",
    "* Si $\\alpha \\to \\infty$, entonces el valor de todos los coeficientes será nulo.\n",
    "\n",
    "Por tanto, para buscar el valor de $\\alpha$ adecuado, tendremos que barrer valores en una escala que cubra valores muy pequeños y valores elevados. Para ello, normalmente se utiliza escala logarítmica aumentando progresivamente el orden  de magnitud. Como ejemplo, podríamos barrer lambda utilizando los siguientes valores $\\alpha = \\{10^{-3},0.01,0.1,1,10,100,1000\\}$, que en escala logarítmica queda como $\\log_{10}({\\alpha}) = \\{-3,-2,-1,0,1,2,3\\}$\n",
    "\n",
    "Vamos a implementar el algoritmo de *ridge regression* variando los valores de $\\alpha$, y viendo cómo esta variación afecta a los coeficientes $\\boldsymbol{\\omega}$ del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#model\n",
    "alpha = 1e-14\n",
    "ridge = Ridge(alpha = alpha).fit(X_train,y_train)\n",
    "w = ridge.coef_\n",
    "norm_w2 = np.dot(w,w.T)\n",
    "    \n",
    "# predicción\n",
    "y_hat = ridge.predict(X_test)\n",
    "\n",
    "# error\n",
    "error_test = np.mean(np.power(y - y_hat,2)) \n",
    "\n",
    "plt.plot(x,g_x,'r',label='$y$')\n",
    "plt.plot(x_i,y_i,'b.',label='$y_i$')\n",
    "plt.plot(x,y_hat,'g',label='$\\hat{y}$')\n",
    "plt.title(f'Grado: {degree}, MSE:{error_test:.2f}\\nalpha: {alpha:g}, $||w||_2^2$ = {norm_w2:.2g}')\n",
    "plt.legend()\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-2, 2))\n",
    "plt.show()\n",
    "\n",
    "coef_names = ['w' + str(i) + ': ' for i in range(1,degree+1)]\n",
    "\n",
    "for f,wi in zip(coef_names,w):\n",
    "    print(f,wi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 2.2: Varía los valores de $\\alpha$ y comprueba cómo afecta al resultado, ¿Cómo varían los coeficientes del modelo?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representamos ahora el valor de los coeficientes del modelo y su norma para distintos valores del parámetro de regularización\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 2.3: Entrene un modelo Ridge para distintos valores de $\\alpha$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 20\n",
    "alphas = np.logspace(-10, -3, n_alphas)\n",
    "\n",
    "coefs = []\n",
    "\n",
    "norm2_coefs = []\n",
    "for a in alphas:\n",
    "    # ... código aquí\n",
    "    # pista: instanciar y entrenar!\n",
    "    ridge = ...\n",
    "\n",
    "    coefs.append(ridge.coef_)\n",
    "    norm2_coefs.append(np.dot(ridge.coef_,ridge.coef_.T))\n",
    "\n",
    "# Display results\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('$w_i$')\n",
    "plt.title('Coeficientes en función de la regularización')\n",
    "plt.axis('tight')\n",
    "\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ax.plot(alphas, norm2_coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('$||\\mathbf{w}||^2_2$')\n",
    "plt.title('Norma de los coeffs en función de la regularización')\n",
    "plt.axis('tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora la pregunta obvia: ¿cuál es el valor óptimo de $\\alpha$? Para responder a este ejercicio de forma correcta debemos probar con distintos valores de $\\alpha$ a partir de los datos, pero ¿cómo calculamos este valor? De nuevo, acudimos a la validación cruzada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Por convención, GridSearchCV siempre intenta MAXIMIZAR los resultados, por lo que\n",
    "# funciones de coste, como MSE, tienen que ir negadas: https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "# Por eso aparece neg_mean_squared_error y por eso hay luego un -1 multiplicando\n",
    "\n",
    "alpha_vector = np.logspace(-15,1,25)\n",
    "param_grid = {'alpha': alpha_vector }\n",
    "grid = GridSearchCV(Ridge(), scoring= 'neg_mean_squared_error', param_grid=param_grid, cv = 5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = -1*np.array(grid.cv_results_['mean_test_score'])\n",
    "plt.semilogx(alpha_vector,scores,'-o')\n",
    "plt.xlabel('alpha',fontsize=16)\n",
    "plt.ylabel('5-Fold MSE')\n",
    "#plt.ylim((0, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijaos cómo podemos acceder al objeto grid\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y cómo podemos acceder al estimador óptimo\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 2.4: Descomente la línea plt.ylim((0, 1))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo ahora con el valor óptimo de $\\alpha$ que hemos encontrado con validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_optimo = grid.best_params_['alpha']\n",
    "ridge = Ridge(alpha = alpha_optimo).fit(X_train,y_train)  # Equivalente a grid.best_estimator_\n",
    "\n",
    "# predicción\n",
    "y_hat = ridge.predict(X_test)\n",
    "w = ridge.coef_\n",
    "norm_w2 = np.dot(w,w.T)\n",
    "\n",
    "# error\n",
    "error_test = np.mean(np.power(y - y_hat,2)) \n",
    "\n",
    "plt.plot(x,g_x,'r',label='$y$')\n",
    "plt.plot(x_i,y_i,'b.',label='$y_i$')\n",
    "plt.plot(x,y_hat,'g',label='$\\hat{y}$')\n",
    "plt.title(f'Grado: {degree}, MSE:{error_test:.2f}\\nalpha: {alpha_optimo:g}, $||w||_2^2$ = {norm_w2:.2g}')\n",
    "plt.legend()\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-2, 2))\n",
    "plt.show()\n",
    "\n",
    "coef_names = ['w' + str(i) + ': ' for i in range(1,degree+1)]\n",
    "\n",
    "for f,wi in zip(coef_names,w):\n",
    "    print(f,wi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 Lasso \n",
    "\n",
    "Se refiere al modelo de regresión lineal con penalización (norma 1) sobre la magnitud de los coeficientes\n",
    "\n",
    "$$\\min_{\\boldsymbol{\\omega}}|| \\mathbf{y} - \\mathbf{X}\\boldsymbol{\\omega}||_2^2 + \\alpha ||\\boldsymbol{\\omega} ||_1$$\n",
    "\n",
    "donde $||\\boldsymbol{\\omega} ||_1 = |\\omega_1| + |\\omega_2| + \\ldots + |\\omega_D|$, siendo $D$ el número de atributos ($\\omega_0$ no se tiene en cuenta en esta penalización).\n",
    "\n",
    "Con esta formulación el algoritmo Lasso permite activar/desactivar coeficientes, de tal forma que se desactivan primero los coeficienes asociados a los atributos que menos influyen en la función de coste (función a minimizar anterior). Con ello:\n",
    "\n",
    "1. Se previene el overfitting, al poder utilizar modelos con menos variables (las desactivamos) y regularizar las variables que se mantienen\n",
    "2. Se gana interpretabilidad, al poder ver cómo evolucionan las variables supervivientes.\n",
    "\n",
    "La activación y desactivación de variables está determinada por el parámetro de regularización $\\alpha$, de la misma forma que sucede con el algoritmo Ridge:\n",
    "\n",
    "* Si $\\alpha = 0$, entonces el resultado coincide con un modelo de [regresión lineal](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Pero ojo, no será igual, ya que sklearn trata de forma diferente Lasso con $\\alpha = 0$ y la regresión lineal; podéis hacer pruebas y veréis como Lasso aplica una regularización, incluso con alphas muy pequeños.\n",
    "* Si $\\alpha \\to \\infty$, entonces el valor de todos los coeficientes será nulo.\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 2.5: Repite los análisis anteriores (Ridge), para el algoritmo [Lasso](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# ... código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 20\n",
    "alphas = np.logspace(-10, 0, n_alphas)\n",
    "\n",
    "coefs = []\n",
    "\n",
    "norm2_coefs = []\n",
    "for a in alphas:\n",
    "    # ... código aquí\n",
    "    lasso = ...\n",
    "\n",
    "    coefs.append(lasso.coef_)\n",
    "    norm2_coefs.append(np.dot(lasso.coef_,lasso.coef_.T))\n",
    "\n",
    "# Display results\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('$w_i$')\n",
    "plt.title('Coeficientes en función de la regularización')\n",
    "plt.axis('tight')\n",
    "\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ax.plot(alphas, norm2_coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('$||\\mathbf{w}||^2_2$')\n",
    "plt.title('Norma de los coeffs en función de la regularización')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_vector = np.logspace(-10,1,25)\n",
    "\n",
    "param_grid = {'alpha': alpha_vector }\n",
    "grid = GridSearchCV(Lasso(), scoring= 'neg_mean_squared_error', param_grid=param_grid, cv = 5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = -1*np.array(grid.cv_results_['mean_test_score'])\n",
    "plt.semilogx(alpha_vector,scores,'-o')\n",
    "plt.xlabel('alpha',fontsize=16)\n",
    "plt.ylabel('5-Fold MSE')\n",
    "plt.ylim((0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_optimo = grid.best_params_['alpha']\n",
    "lasso = Lasso(alpha = alpha_optimo).fit(X_train,y_train) # Equivalente a grid.best_estimator_\n",
    "\n",
    "# predicción\n",
    "y_hat = lasso.predict(X_test)\n",
    "w = lasso.coef_\n",
    "norm_w2 = np.dot(w,w.T)\n",
    "\n",
    "# error\n",
    "error_test = np.mean(np.power(y - y_hat,2)) \n",
    "\n",
    "\n",
    "plt.plot(x,g_x,'r',label='$y$')\n",
    "plt.plot(x_i,y_i,'b.',label='$y_i$')\n",
    "plt.plot(x,y_hat,'g',label='$\\hat{y}$')\n",
    "plt.title(f'Grado: {degree}, MSE:{error_test:.2f}\\nalpha: {alpha_optimo:g}, $||w||_2^2$ = {norm_w2:.2g}')\n",
    "plt.legend()\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-2, 2))\n",
    "plt.show()\n",
    "\n",
    "coef_names = ['w' + str(i) + ': ' for i in range(1,degree+1)]\n",
    "\n",
    "for f,wi in zip(coef_names,w):\n",
    "    print(f,wi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 2.6: A la vista de los resultados, ¿qué diferencias entre Ridge y Lasso destacarías?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Regularización sobre algoritmos de clasificación\n",
    "\n",
    "Algunos algoritmos de clasificación también tienen un parámetro que permite controlar su complejidad. En el caso de [regresión logística](http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), la función de coste a minimizar es de la forma:\n",
    "\n",
    "$$J(\\boldsymbol{\\omega}) = -\\sum_{i=1}^N y^{(i)}\\log{(\\theta(\\mathbf{x}^{(i)}))} + (1-y^{(i)})\\log{\\left(1-\\theta(\\mathbf{x}^{(i)})\\right)}  = \\sum_{i=1}^N \\log{\\left(1+ e^{-y^{(i)}\\boldsymbol{\\omega}^T\\mathbf{x}^{(i)}}\\right)}  $$\n",
    "\n",
    "donde $\\theta(\\mathbf{x}^{(i)}) = \\frac{1}{1+e^{-\\boldsymbol{\\omega}^T\\mathbf{x}^{(i)}}}$. En su versión \"regularizada\", la función de coste pasa a ser:\n",
    "\n",
    "$$J(\\boldsymbol{\\omega}) = \\frac{1}{2}||\\boldsymbol{\\omega}||_2^2 + C \\sum_{i=1}^N \\log{\\left(1+ e^{-y^{(i)}\\boldsymbol{\\omega}^T\\mathbf{x}^{(i)}}\\right)}$$\n",
    "\n",
    "El **coste $C$** es el parámetro libre que permite controlar la complejidad del algoritmo, penalizando los errores que se comenten en clasificación. Este parámetro supone un compromiso entre la exactitud de la solución y la complejidad del algoritmo, en ese sentido es similar al parámetro de regularización $\\alpha$ que utilizamos en Ridge y Lasso. En este caso, de forma intuitiva podemos decir que **$C$ se comporta como  $1/\\alpha$**. Así:\n",
    "\n",
    "- Cuanto mayor es $C$ (menor es $\\alpha$), más penalizamos los errores en clasificación y la frontera se ajusta mucho a los datos (en el caso extremo se ajustará perfectamente). Riesgo de overfitting pero con potencial menor error de clasificación.\n",
    "\n",
    "\n",
    "- Cuanto menor es $C$ (mayor es $\\alpha$), menos penalizamos los errores en clasificación y tenderemos hacia modelos más sencillos (fronteras menos ajustadas, menor riesgo de overfitting pero potencialmente con más error de clasificación)\n",
    "\n",
    "NOTA: por defecto, $C=1$ en scikit-learn.\n",
    "\n",
    "![](./figuras/Sesgo_varianza_parametros.png)\n",
    "\n",
    "\n",
    "\n",
    "Veamos cómo funciona $C$ sobre los ejemplos de clasificación que hemos visto anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo1\n",
    "ejemplo1 = pd.read_csv(\"./data/ex2data1.txt\", sep=\",\", header=None, names=['x1', 'x2','label'])\n",
    "\n",
    "# ejemplo2\n",
    "ejemplo2 = pd.read_csv(\"./data/ex2data2.txt\", sep=\",\", header=None, names=['x1', 'x2','label'])\n",
    "\n",
    "# ejemplo 3: Problema XOR \n",
    "np.random.seed(0)\n",
    "\n",
    "# -- parameters\n",
    "N     = 800\n",
    "mu    = 1.5      # Cambia este valor\n",
    "sigma = 1      # Cambia este valor\n",
    "\n",
    "# variables auxiliares\n",
    "unos = np.ones(int(N/4))\n",
    "random4 = sigma*np.random.randn(int(N/4),1)\n",
    "random2 = sigma*np.random.randn(int(N/2),1)\n",
    "\n",
    "# -- features\n",
    "y3 = np.concatenate([-1*unos,       unos,          unos,         -1*unos]) \n",
    "X1 = np.concatenate([-mu + random4, mu + random4, -mu + random4, mu + random4])\n",
    "X2 = np.concatenate([+mu + random2,               -mu + random2])\n",
    "X3 = np.hstack((X1,X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.scatter(ejemplo1['x1'], ejemplo1['x2'], c=ejemplo1['label'], cmap=CM_BRIGHT)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.title('Ejemplo 1')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.scatter(ejemplo2['x1'], ejemplo2['x2'], c=ejemplo2['label'], cmap=CM_BRIGHT)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.title('Ejemplo 2')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(X3[:,0], X3[:,1], c=y3, cmap=CM_BRIGHT)\n",
    "plt.xlabel(\"$x_1$\", fontsize=16)\n",
    "plt.ylabel(\"$x_2$\", fontsize=16)\n",
    "plt.title('Ejemplo 3')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# preparamos los datos\n",
    "data1 = ejemplo1.values\n",
    "X1 = data1[:,0:2]\n",
    "y1 = data1[:,-1]\n",
    "\n",
    "# creamos el modelo\n",
    "lr1 = LogisticRegression()\n",
    "\n",
    "# ajustamos con los datos disponibles\n",
    "lr1.fit(X1, y1)\n",
    "plot_decision_boundary(X1, y1, lr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C grande (ANTES DE EJECUTAR TRATA DE PENSAR CÓMO SERÁ EL RESULTADO!)\n",
    "lr1 = LogisticRegression(C = 1000)\n",
    "lr1.fit(X1,y1)\n",
    "plot_decision_boundary(X1,y1,0.05,lr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C pequeño (ANTES DE EJECUTAR TRATA DE PENSAR CÓMO SERÁ EL RESULTADO!)\n",
    "lr1 = LogisticRegression(C = 0.4)\n",
    "lr1.fit(X1,y1)\n",
    "plot_decision_boundary(X1,y1,0.05,lr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 2.7: Aplica el algoritmo de regresión logística sobre los ejemplos anteriores 2 y 3, variando el valor de $C$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 2\n",
    "# ... código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 3\n",
    "# ... código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No funciona bien, no? La razón es que la regresión logística es un modelo lineal, y por tanto no funciona para distribuciones no linealmente separables. Para poder aplicarla, necesitamos transformar los datos, por ejemplo añadiendo Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly     = PolynomialFeatures(2)\n",
    "X2poly   = poly.fit_transform(X2)\n",
    "\n",
    "# creamos el modelo\n",
    "lr2_poly = LogisticRegression(C=0.4)\n",
    "\n",
    "# ajustamos con los datos disponibles\n",
    "lr2_poly.fit(X2poly, y2)\n",
    "plot_decision_boundary_poly(X2, y2, 0.05, lr2_poly, poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly     = PolynomialFeatures(degree=6)\n",
    "X3poly   = poly.fit_transform(X3)\n",
    "\n",
    "# creamos el modelo\n",
    "lr3_poly = LogisticRegression(C=0.0000001)\n",
    "\n",
    "# ajustamos con los datos disponibles\n",
    "lr3_poly.fit(X3poly, y3)\n",
    "plot_decision_boundary_poly(X3, y3, 0.05, lr3_poly, poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero cuidado, no hagamos trampas, ¿cómo tenemos que seleccionar el valor de $C$ adecuado para el problema?\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 2.8: Calcula el valor óptimo de $C$ para el ejemplo 3\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "poly     = PolynomialFeatures(2)\n",
    "X3poly   = poly.fit_transform(X3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3poly, y3, test_size = 0.3, shuffle = True, random_state = 0)\n",
    "\n",
    "vectorC = np.logspace(-10, 2, 20)\n",
    "param_grid = {'C': vectorC}\n",
    "\n",
    "# ... código aquí\n",
    "grid = ...\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "print(\"test-set score: {:.2f}\".format(grid.score(X_test, y_test)))\n",
    "\n",
    "scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "plt.semilogx(vectorC,scores,'-o')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('5-Fold ACC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "EJERCICIO 2.9: Representa la frontera de separación para el valor de $C$ óptimo\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... código aquí\n",
    "lr_opt = ...\n",
    "plot_decision_boundary_poly(X3, y3, lr_opt, poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de que la búsqueda de parámetros libres nos proporcione un valor óptimo, quizá éste está demasiado ajustado, por lo tanto es recomendable representar el resultado, en la medida de lo posible, e interpretarlo de forma correcta.\n",
    "\n",
    "Casi todos los algoritmos de machine learning tienen un parámetro que controla la complejidad del mismo, y tenemos que conocer cómo afecta al resultado. Eso sí, para calcular su valor, siempre utilizaremos una estrategia adecuada de selección del modelo (normalmente validación cruzada). Y nunca, nunca miramos test antes de evaluar!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
